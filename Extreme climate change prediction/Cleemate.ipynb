{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "wvJTqetxeUpQ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define column names to assign\n",
        "column_names = ['location', 'time', 'deg_min', 'deg_max', 'hum_min', 'hum_max', 'humidity', 'temperature', 'weather_code', 'wind_direction', 'wind_speed']\n",
        "\n",
        "# List of the dataset filenames\n",
        "dataset_files = [\n",
        "    'kecamatanforecast-jakarta.csv',\n",
        "    'kecamatanforecast-jambi.csv',\n",
        "    'kecamatanforecast-jawatengah.csv',\n",
        "    'kecamatanforecast-jawatimur.csv',\n",
        "    'kecamatanforecast-sumut.csv'\n",
        "]\n",
        "\n",
        "# Read each dataset, assign column names, and drop unwanted columns\n",
        "datasets = []\n",
        "for file in dataset_files:\n",
        "    # Read the CSV file with \";\" as the separator\n",
        "    df = pd.read_csv(file, sep=';', header=None)\n",
        "\n",
        "    # Assign column names\n",
        "    df.columns = column_names\n",
        "\n",
        "    # Split the 'time' column into 'date' and 'time'\n",
        "    df[['date', 'time']] = df['time'].str.split(' ', expand=True)\n",
        "\n",
        "    # Reorder the columns to have 'date' first, followed by 'time'\n",
        "    df = df[['date', 'time'] + [col for col in df.columns if col not in ['date', 'time']]]\n",
        "\n",
        "    # Drop unnecessary columns\n",
        "    df = df.drop(columns=['deg_min', 'deg_max', 'hum_min', 'hum_max', 'wind_direction'])\n",
        "\n",
        "    # Append the cleaned dataset to the list\n",
        "    datasets.append(df)\n",
        "\n",
        "# Combine all datasets into one\n",
        "combined_df = pd.concat(datasets, ignore_index=True)\n",
        "\n",
        "# Show the updated dataset (optional)\n",
        "print(combined_df.head())\n",
        "\n",
        "# Save the combined dataframe to a new file\n",
        "combined_df.to_csv('cleemate-dataset.csv', sep=';', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHBjzFX5mqAJ",
        "outputId": "cffef03a-26af-4428-fc52-bd1f5d80e788"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         date      time  location  humidity  temperature  weather_code  \\\n",
            "0  2024-11-25  00:00:00    501191        88           26             4   \n",
            "1  2024-11-25  01:00:00    501191        81           27             4   \n",
            "2  2024-11-25  02:00:00    501191        73           29             4   \n",
            "3  2024-11-25  03:00:00    501191        66           31             4   \n",
            "4  2024-11-25  04:00:00    501191        63           31             4   \n",
            "\n",
            "   wind_speed  \n",
            "0           1  \n",
            "1           1  \n",
            "2           1  \n",
            "3           1  \n",
            "4           1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the kecamatanforecast-jawatimur-fix dataset (semicolon-separated)\n",
        "df_forecast = pd.read_csv('cleemate-dataset.csv', sep=';')\n",
        "\n",
        "# Load the kecamatan_geofeatures dataset (semicolon-separated)\n",
        "df_geofeatures = pd.read_csv('kecamatan_geofeatures.csv', sep=';')\n",
        "\n",
        "# Merge the datasets on the 'location' column to get the corresponding 'kota' and 'provinsi' values\n",
        "merged_df = pd.merge(df_forecast, df_geofeatures[['location', 'kota', 'provinsi']], on='location', how='left')\n",
        "\n",
        "# Replace 'location' column with 'kota' column\n",
        "merged_df['location'] = merged_df['kota']\n",
        "\n",
        "# Drop the 'kota' column, as we no longer need it\n",
        "merged_df = merged_df.drop(columns=['kota'])\n",
        "\n",
        "# Rearrange columns so that 'provinsi' comes after 'location'\n",
        "columns = ['location', 'provinsi'] + [col for col in merged_df.columns if col not in ['location', 'provinsi']]\n",
        "merged_df = merged_df[columns]\n",
        "\n",
        "# Show the updated dataframe (first few rows)\n",
        "print(merged_df.head())\n",
        "\n",
        "# Optionally, save the updated dataframe to a new CSV file\n",
        "merged_df.to_csv('cleemate-dataset-fix.csv', sep=';', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf6G28z4N1Te",
        "outputId": "fc8a8f9b-416b-4cb6-ea44-652b6653e0ba"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             location     provinsi        date      time  humidity  \\\n",
            "0  Kota Jakarta Timur  DKI Jakarta  2024-11-25  00:00:00        88   \n",
            "1  Kota Jakarta Timur  DKI Jakarta  2024-11-25  01:00:00        81   \n",
            "2  Kota Jakarta Timur  DKI Jakarta  2024-11-25  02:00:00        73   \n",
            "3  Kota Jakarta Timur  DKI Jakarta  2024-11-25  03:00:00        66   \n",
            "4  Kota Jakarta Timur  DKI Jakarta  2024-11-25  04:00:00        63   \n",
            "\n",
            "   temperature  weather_code  wind_speed  \n",
            "0           26             4           1  \n",
            "1           27             4           1  \n",
            "2           29             4           1  \n",
            "3           31             4           1  \n",
            "4           31             4           1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the kecamatanforecast-jawatimur-fix dataset (semicolon-separated)\n",
        "df_forecast = pd.read_csv('cleemate-dataset-fix.csv', sep=';')\n",
        "\n",
        "# Load the weather dataset (semicolon-separated)\n",
        "df_weather = pd.read_csv('weather.csv', sep=';')\n",
        "\n",
        "# Merge the datasets on the 'weather_code' column to get the corresponding 'weather' values\n",
        "merged_df = pd.merge(df_forecast, df_weather[['weather_code', 'weather']], on='weather_code', how='left')\n",
        "\n",
        "# Optionally, you can rename the 'weather' column to a more descriptive name, but do not replace 'weather_code'\n",
        "# If you want to keep 'weather_code' and 'weather' columns, no need to replace 'weather_code'\n",
        "# Just ensure the 'weather' column is included in the merged dataset.\n",
        "\n",
        "# Show the updated dataframe (first few rows)\n",
        "print(merged_df.head())\n",
        "\n",
        "# Optionally, save the updated dataframe to a new CSV file\n",
        "merged_df.to_csv('cleemate-dataset-fix.csv', sep=';', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCO2Se4vXXzs",
        "outputId": "c4695b25-14a2-4e5d-d94d-1773a2edf25a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             location     provinsi        date      time  humidity  \\\n",
            "0  Kota Jakarta Timur  DKI Jakarta  2024-11-25  00:00:00        88   \n",
            "1  Kota Jakarta Timur  DKI Jakarta  2024-11-25  01:00:00        81   \n",
            "2  Kota Jakarta Timur  DKI Jakarta  2024-11-25  02:00:00        73   \n",
            "3  Kota Jakarta Timur  DKI Jakarta  2024-11-25  03:00:00        66   \n",
            "4  Kota Jakarta Timur  DKI Jakarta  2024-11-25  04:00:00        63   \n",
            "\n",
            "   temperature  weather_code  wind_speed        weather  \n",
            "0           26             4           1  Berawan Tebal  \n",
            "1           27             4           1  Berawan Tebal  \n",
            "2           29             4           1  Berawan Tebal  \n",
            "3           31             4           1  Berawan Tebal  \n",
            "4           31             4           1  Berawan Tebal  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset (semicolon-separated)\n",
        "df_forecast = pd.read_csv('cleemate-dataset-fix.csv', sep=';')\n",
        "\n",
        "# Create necessary columns first (before imputation)\n",
        "df_forecast['temp_change'] = df_forecast['temperature'].diff().fillna(0)\n",
        "df_forecast['wind_speed_change'] = df_forecast['wind_speed'].diff().fillna(0)\n",
        "df_forecast['humidity_change'] = df_forecast['humidity'].diff().fillna(0)\n",
        "\n",
        "# Create lag features for 1-day lookback (shift the values by 1)\n",
        "df_forecast['temp_previous_day'] = df_forecast['temperature'].shift(1)\n",
        "df_forecast['wind_speed_previous_day'] = df_forecast['wind_speed'].shift(1)\n",
        "df_forecast['humidity_previous_day'] = df_forecast['humidity'].shift(1)\n",
        "\n",
        "# Rolling averages over the past 5 columns for temperature, wind speed, and humidity\n",
        "df_forecast['rolling_temp'] = df_forecast['temperature'].rolling(window=5).mean()\n",
        "df_forecast['rolling_wind'] = df_forecast['wind_speed'].rolling(window=5).mean()\n",
        "df_forecast['rolling_humidity'] = df_forecast['humidity'].rolling(window=5).mean()\n",
        "\n",
        "# Handle missing values by imputing (using median or mean)\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "df_forecast[['humidity', 'temperature', 'wind_speed', 'temp_change', 'wind_speed_change',\n",
        "             'humidity_change', 'temp_previous_day', 'wind_speed_previous_day',\n",
        "             'humidity_previous_day', 'rolling_temp', 'rolling_wind', 'rolling_humidity']] = imputer.fit_transform(\n",
        "    df_forecast[['humidity', 'temperature', 'wind_speed', 'temp_change', 'wind_speed_change',\n",
        "                 'humidity_change', 'temp_previous_day', 'wind_speed_previous_day',\n",
        "                 'humidity_previous_day', 'rolling_temp', 'rolling_wind', 'rolling_humidity']])\n",
        "\n",
        "# Convert 'weather_code' into one-hot encoded features\n",
        "weather_encoder = OneHotEncoder(sparse_output=False)\n",
        "weather_code_encoded = weather_encoder.fit_transform(df_forecast[['weather_code']])\n",
        "\n",
        "# Create a DataFrame from the one-hot encoded features and join with the original dataframe\n",
        "weather_code_df = pd.DataFrame(weather_code_encoded, columns=weather_encoder.get_feature_names_out(['weather_code']))\n",
        "df_forecast = pd.concat([df_forecast, weather_code_df], axis=1)\n",
        "\n",
        "# Define extreme fluctuation (label = 1 for extreme change, 0 otherwise)\n",
        "df_forecast['extreme_fluctuation'] = ((df_forecast['temp_change'].abs() > 5) |\n",
        "                                      (df_forecast['wind_speed_change'].abs() > 10) |\n",
        "                                      (df_forecast['humidity_change'].abs() > 10)).astype(int)\n",
        "\n",
        "# Drop rows with missing data due to lag or rolling operations\n",
        "df_forecast = df_forecast.dropna(subset=['extreme_fluctuation'])\n",
        "\n",
        "# Features (X) and Target (y)\n",
        "X = df_forecast[['humidity', 'temperature', 'wind_speed', 'temp_change', 'wind_speed_change',\n",
        "                 'humidity_change', 'temp_previous_day', 'wind_speed_previous_day',\n",
        "                 'humidity_previous_day', 'rolling_temp', 'rolling_wind', 'rolling_humidity'] + list(weather_code_df.columns)]\n",
        "y = df_forecast['extreme_fluctuation']\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Handle class imbalance using SMOTE (oversampling the minority class)\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "-qNVhqu755GA"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=(X_train_resampled.shape[1],)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification (0 or 1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_resampled, y_train_resampled, epochs=50, batch_size=64, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNWNLaBrNTRT",
        "outputId": "97357baa-d67c-4349-e04d-05358c183552"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9461 - loss: 0.1254 - val_accuracy: 0.9849 - val_loss: 0.0325\n",
            "Epoch 2/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9887 - loss: 0.0304 - val_accuracy: 0.9958 - val_loss: 0.0117\n",
            "Epoch 3/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0196 - val_accuracy: 0.9938 - val_loss: 0.0140\n",
            "Epoch 4/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0159 - val_accuracy: 0.9975 - val_loss: 0.0066\n",
            "Epoch 5/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0128 - val_accuracy: 0.9958 - val_loss: 0.0112\n",
            "Epoch 6/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0113 - val_accuracy: 0.9962 - val_loss: 0.0103\n",
            "Epoch 7/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0102 - val_accuracy: 0.9952 - val_loss: 0.0115\n",
            "Epoch 8/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0094 - val_accuracy: 0.9987 - val_loss: 0.0035\n",
            "Epoch 9/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0087 - val_accuracy: 0.9971 - val_loss: 0.0071\n",
            "Epoch 10/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0084 - val_accuracy: 0.9984 - val_loss: 0.0042\n",
            "Epoch 11/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0081 - val_accuracy: 0.9985 - val_loss: 0.0049\n",
            "Epoch 12/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0075 - val_accuracy: 0.9985 - val_loss: 0.0038\n",
            "Epoch 13/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0066 - val_accuracy: 0.9981 - val_loss: 0.0043\n",
            "Epoch 14/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0070 - val_accuracy: 0.9990 - val_loss: 0.0025\n",
            "Epoch 15/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0060 - val_accuracy: 0.9988 - val_loss: 0.0029\n",
            "Epoch 16/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0066 - val_accuracy: 0.9981 - val_loss: 0.0043\n",
            "Epoch 17/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0062 - val_accuracy: 0.9991 - val_loss: 0.0024\n",
            "Epoch 18/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0058 - val_accuracy: 0.9988 - val_loss: 0.0033\n",
            "Epoch 19/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0067 - val_accuracy: 0.9986 - val_loss: 0.0033\n",
            "Epoch 20/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0055 - val_accuracy: 0.9994 - val_loss: 0.0022\n",
            "Epoch 21/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0049 - val_accuracy: 0.9993 - val_loss: 0.0020\n",
            "Epoch 22/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0058 - val_accuracy: 0.9994 - val_loss: 0.0016\n",
            "Epoch 23/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0052 - val_accuracy: 0.9990 - val_loss: 0.0025\n",
            "Epoch 24/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0046 - val_accuracy: 0.9990 - val_loss: 0.0029\n",
            "Epoch 25/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.9989 - val_loss: 0.0029\n",
            "Epoch 26/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0053 - val_accuracy: 0.9992 - val_loss: 0.0022\n",
            "Epoch 27/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0049 - val_accuracy: 0.9994 - val_loss: 0.0019\n",
            "Epoch 28/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.9987 - val_loss: 0.0027\n",
            "Epoch 29/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0044 - val_accuracy: 0.9964 - val_loss: 0.0102\n",
            "Epoch 30/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0046 - val_accuracy: 0.9993 - val_loss: 0.0017\n",
            "Epoch 31/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0039 - val_accuracy: 0.9991 - val_loss: 0.0021\n",
            "Epoch 32/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0040 - val_accuracy: 0.9989 - val_loss: 0.0024\n",
            "Epoch 33/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0036 - val_accuracy: 0.9984 - val_loss: 0.0039\n",
            "Epoch 34/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0044 - val_accuracy: 0.9994 - val_loss: 0.0014\n",
            "Epoch 35/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 0.9994 - val_loss: 0.0016\n",
            "Epoch 36/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.9991 - val_loss: 0.0025\n",
            "Epoch 37/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0035 - val_accuracy: 0.9985 - val_loss: 0.0030\n",
            "Epoch 38/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0034 - val_accuracy: 0.9980 - val_loss: 0.0049\n",
            "Epoch 39/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 0.9995 - val_loss: 0.0014\n",
            "Epoch 40/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0032 - val_accuracy: 0.9994 - val_loss: 0.0013\n",
            "Epoch 41/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0035 - val_accuracy: 0.9995 - val_loss: 0.0016\n",
            "Epoch 42/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 0.9991 - val_loss: 0.0025\n",
            "Epoch 43/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0033 - val_accuracy: 0.9990 - val_loss: 0.0022\n",
            "Epoch 44/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 0.9993 - val_loss: 0.0016\n",
            "Epoch 45/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.9983 - val_loss: 0.0032\n",
            "Epoch 46/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0038 - val_accuracy: 0.9984 - val_loss: 0.0046\n",
            "Epoch 47/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 0.9996 - val_loss: 0.0012\n",
            "Epoch 48/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.9990 - val_loss: 0.0025\n",
            "Epoch 49/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 0.9991 - val_loss: 0.0028\n",
            "Epoch 50/50\n",
            "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 0.9994 - val_loss: 0.0013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "\n",
        "print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred)}\")\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpC2mEYbBnlB",
        "outputId": "48a85ac6-8a1b-46e4-923c-f7b4f0e5f8d0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9993 - loss: 0.0013\n",
            "Test Accuracy: 99.94%\n",
            "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
            "Precision: 0.9961923411662315\n",
            "Recall: 0.9994542676271556\n",
            "F1 Score: 0.997820638552904\n",
            "[[56008    35]\n",
            " [    5  9157]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model to the runtime (local file system)\n",
        "model.save('/content/cleemate-model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFE1ZO10VHCb",
        "outputId": "afbbd727-6095-44ba-94a8-af4b7338468a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}