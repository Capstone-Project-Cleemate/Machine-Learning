{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gttGh5eKrCd7"
   },
   "source": [
    "# **Extreme Climate Change Prediction (CLEEMATE)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "So6kEk7gq3Zb"
   },
   "source": [
    "# Resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wvJTqetxeUpQ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "be8PbLqtpoDk"
   },
   "source": [
    "# Gathering Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CHBjzFX5mqAJ",
    "outputId": "ad7814cc-adb2-43aa-dc0f-a541a4587c79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date      time  location  humidity  temperature  weather_code  \\\n",
      "0  2024-11-25  00:00:00    501191        88           26             4   \n",
      "1  2024-11-25  01:00:00    501191        81           27             4   \n",
      "2  2024-11-25  02:00:00    501191        73           29             4   \n",
      "3  2024-11-25  03:00:00    501191        66           31             4   \n",
      "4  2024-11-25  04:00:00    501191        63           31             4   \n",
      "\n",
      "   wind_speed  \n",
      "0           1  \n",
      "1           1  \n",
      "2           1  \n",
      "3           1  \n",
      "4           1  \n"
     ]
    }
   ],
   "source": [
    "# Define column names to assign\n",
    "column_names = ['location', 'time', 'deg_min', 'deg_max', 'hum_min', 'hum_max', 'humidity', 'temperature', 'weather_code', 'wind_direction', 'wind_speed']\n",
    "\n",
    "# List of the dataset filenames\n",
    "dataset_files = [\n",
    "    'kecamatanforecast-jakarta.csv',\n",
    "    'kecamatanforecast-jambi.csv',\n",
    "    'kecamatanforecast-jawatengah.csv',\n",
    "    'kecamatanforecast-jawatimur.csv',\n",
    "    'kecamatanforecast-sumut.csv'\n",
    "]\n",
    "\n",
    "# Read each dataset, assign column names, and drop unwanted columns\n",
    "datasets = []\n",
    "for file in dataset_files:\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file, sep=';', header=None)\n",
    "\n",
    "    # Assign column names\n",
    "    df.columns = column_names\n",
    "\n",
    "    # Split the 'time' column into 'date' and 'time'\n",
    "    df[['date', 'time']] = df['time'].str.split(' ', expand=True)\n",
    "\n",
    "    # Reorder the columns to have 'date' first, followed by 'time'\n",
    "    df = df[['date', 'time'] + [col for col in df.columns if col not in ['date', 'time']]]\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df = df.drop(columns=['deg_min', 'deg_max', 'hum_min', 'hum_max', 'wind_direction'])\n",
    "\n",
    "    # Append the cleaned dataset to the list\n",
    "    datasets.append(df)\n",
    "\n",
    "# Combine all datasets into one\n",
    "combined_df = pd.concat(datasets, ignore_index=True)\n",
    "\n",
    "# Show the updated dataset (optional)\n",
    "print(combined_df.head())\n",
    "\n",
    "# Save the combined dataframe to a new file\n",
    "combined_df.to_csv('cleemate-dataset.csv', sep=';', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WTBfaEIp-X9"
   },
   "source": [
    "# Merge Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hf6G28z4N1Te",
    "outputId": "89efed58-12bf-43d7-a693-e25536a1bd9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             location     provinsi        date      time  humidity  \\\n",
      "0  Kota Jakarta Timur  DKI Jakarta  2024-11-25  00:00:00        88   \n",
      "1  Kota Jakarta Timur  DKI Jakarta  2024-11-25  01:00:00        81   \n",
      "2  Kota Jakarta Timur  DKI Jakarta  2024-11-25  02:00:00        73   \n",
      "3  Kota Jakarta Timur  DKI Jakarta  2024-11-25  03:00:00        66   \n",
      "4  Kota Jakarta Timur  DKI Jakarta  2024-11-25  04:00:00        63   \n",
      "\n",
      "   temperature  weather_code  wind_speed  \n",
      "0           26             4           1  \n",
      "1           27             4           1  \n",
      "2           29             4           1  \n",
      "3           31             4           1  \n",
      "4           31             4           1  \n"
     ]
    }
   ],
   "source": [
    "# Load the kecamatanforecast-jawatimur-fix dataset\n",
    "df_forecast = pd.read_csv('cleemate-dataset.csv', sep=';')\n",
    "\n",
    "# Load the kecamatan_geofeatures dataset\n",
    "df_geofeatures = pd.read_csv('kecamatan_geofeatures.csv', sep=';')\n",
    "\n",
    "# Merge the datasets on the 'location' column to get the corresponding 'kota' and 'provinsi' values\n",
    "merged_df = pd.merge(df_forecast, df_geofeatures[['location', 'kota', 'provinsi']], on='location', how='left')\n",
    "\n",
    "# Replace 'location' column with 'kota' column\n",
    "merged_df['location'] = merged_df['kota']\n",
    "\n",
    "# Drop the 'kota' column, as we no longer need it\n",
    "merged_df = merged_df.drop(columns=['kota'])\n",
    "\n",
    "# Rearrange columns so that 'provinsi' comes after 'location'\n",
    "columns = ['location', 'provinsi'] + [col for col in merged_df.columns if col not in ['location', 'provinsi']]\n",
    "merged_df = merged_df[columns]\n",
    "\n",
    "# Show the updated dataframe (first few rows)\n",
    "print(merged_df.head())\n",
    "\n",
    "# Optionally, save the updated dataframe to a new CSV file\n",
    "merged_df.to_csv('cleemate-dataset-fix.csv', sep=';', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oCO2Se4vXXzs",
    "outputId": "174ee976-d5e8-4d5e-d0d1-342087d0a949"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             location     provinsi        date      time  humidity  \\\n",
      "0  Kota Jakarta Timur  DKI Jakarta  2024-11-25  00:00:00        88   \n",
      "1  Kota Jakarta Timur  DKI Jakarta  2024-11-25  01:00:00        81   \n",
      "2  Kota Jakarta Timur  DKI Jakarta  2024-11-25  02:00:00        73   \n",
      "3  Kota Jakarta Timur  DKI Jakarta  2024-11-25  03:00:00        66   \n",
      "4  Kota Jakarta Timur  DKI Jakarta  2024-11-25  04:00:00        63   \n",
      "\n",
      "   temperature  weather_code  wind_speed        weather  \n",
      "0           26             4           1  Berawan Tebal  \n",
      "1           27             4           1  Berawan Tebal  \n",
      "2           29             4           1  Berawan Tebal  \n",
      "3           31             4           1  Berawan Tebal  \n",
      "4           31             4           1  Berawan Tebal  \n"
     ]
    }
   ],
   "source": [
    "# Load the kecamatanforecast-jawatimur-fix dataset\n",
    "df_forecast = pd.read_csv('cleemate-dataset-fix.csv', sep=';')\n",
    "\n",
    "# Load the weather dataset\n",
    "df_weather = pd.read_csv('weather.csv', sep=';')\n",
    "\n",
    "# Merge the datasets on the 'weather_code' column to get the corresponding 'weather' values\n",
    "merged_df = pd.merge(df_forecast, df_weather[['weather_code', 'weather']], on='weather_code', how='left')\n",
    "\n",
    "# Show the updated dataframe (first few rows)\n",
    "print(merged_df.head())\n",
    "\n",
    "# Optionally, save the updated dataframe to a new CSV file\n",
    "merged_df.to_csv('cleemate-dataset-fix.csv', sep=';', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCUGFDfvqdF1"
   },
   "source": [
    "# Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-qNVhqu755GA"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df_forecast = pd.read_csv('cleemate-dataset-fix.csv', sep=';')\n",
    "\n",
    "# Create necessary columns first (before imputation)\n",
    "df_forecast['temp_change'] = df_forecast['temperature'].diff().fillna(0)\n",
    "df_forecast['wind_speed_change'] = df_forecast['wind_speed'].diff().fillna(0)\n",
    "df_forecast['humidity_change'] = df_forecast['humidity'].diff().fillna(0)\n",
    "\n",
    "# Create lag features for 1-day lookback (shift the values by 1)\n",
    "df_forecast['temp_previous_day'] = df_forecast['temperature'].shift(1)\n",
    "df_forecast['wind_speed_previous_day'] = df_forecast['wind_speed'].shift(1)\n",
    "df_forecast['humidity_previous_day'] = df_forecast['humidity'].shift(1)\n",
    "\n",
    "# Rolling averages over the past 5 columns for temperature, wind speed, and humidity\n",
    "df_forecast['rolling_temp'] = df_forecast['temperature'].rolling(window=5).mean()\n",
    "df_forecast['rolling_wind'] = df_forecast['wind_speed'].rolling(window=5).mean()\n",
    "df_forecast['rolling_humidity'] = df_forecast['humidity'].rolling(window=5).mean()\n",
    "\n",
    "# Handle missing values by imputing (using median or mean)\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df_forecast[['humidity', 'temperature', 'wind_speed', 'temp_change', 'wind_speed_change',\n",
    "             'humidity_change', 'temp_previous_day', 'wind_speed_previous_day',\n",
    "             'humidity_previous_day', 'rolling_temp', 'rolling_wind', 'rolling_humidity']] = imputer.fit_transform(\n",
    "    df_forecast[['humidity', 'temperature', 'wind_speed', 'temp_change', 'wind_speed_change',\n",
    "                 'humidity_change', 'temp_previous_day', 'wind_speed_previous_day',\n",
    "                 'humidity_previous_day', 'rolling_temp', 'rolling_wind', 'rolling_humidity']])\n",
    "\n",
    "# Convert 'weather_code' into one-hot encoded features\n",
    "weather_encoder = OneHotEncoder(sparse_output=False)\n",
    "weather_code_encoded = weather_encoder.fit_transform(df_forecast[['weather_code']])\n",
    "\n",
    "# Create a DataFrame from the one-hot encoded features and join with the original dataframe\n",
    "weather_code_df = pd.DataFrame(weather_code_encoded, columns=weather_encoder.get_feature_names_out(['weather_code']))\n",
    "df_forecast = pd.concat([df_forecast, weather_code_df], axis=1)\n",
    "\n",
    "# Define extreme fluctuation (label = 1 for extreme change, 0 otherwise)\n",
    "df_forecast['extreme_fluctuation'] = ((df_forecast['temp_change'].abs() > 5) |\n",
    "                                      (df_forecast['wind_speed_change'].abs() > 10) |\n",
    "                                      (df_forecast['humidity_change'].abs() > 10)).astype(int)\n",
    "\n",
    "# Drop rows with missing data due to lag or rolling operations\n",
    "df_forecast = df_forecast.dropna(subset=['extreme_fluctuation'])\n",
    "\n",
    "# Features (X) and Target (y)\n",
    "X = df_forecast[['humidity', 'temperature', 'wind_speed', 'temp_change', 'wind_speed_change',\n",
    "                 'humidity_change', 'temp_previous_day', 'wind_speed_previous_day',\n",
    "                 'humidity_previous_day', 'rolling_temp', 'rolling_wind', 'rolling_humidity'] + list(weather_code_df.columns)]\n",
    "y = df_forecast['extreme_fluctuation']\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Handle class imbalance using SMOTE (oversampling the minority class)\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQygp3xwqhvF"
   },
   "source": [
    "# Build and Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KNWNLaBrNTRT",
    "outputId": "f02b97a6-6dd5-402d-ec93-c403a618f8ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9485 - loss: 0.1210 - val_accuracy: 0.9862 - val_loss: 0.0279\n",
      "Epoch 2/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.9885 - loss: 0.0300 - val_accuracy: 0.9937 - val_loss: 0.0146\n",
      "Epoch 3/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0205 - val_accuracy: 0.9963 - val_loss: 0.0101\n",
      "Epoch 4/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0153 - val_accuracy: 0.9926 - val_loss: 0.0145\n",
      "Epoch 5/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0126 - val_accuracy: 0.9981 - val_loss: 0.0055\n",
      "Epoch 6/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0107 - val_accuracy: 0.9975 - val_loss: 0.0057\n",
      "Epoch 7/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0104 - val_accuracy: 0.9962 - val_loss: 0.0088\n",
      "Epoch 8/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0094 - val_accuracy: 0.9979 - val_loss: 0.0061\n",
      "Epoch 9/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0086 - val_accuracy: 0.9968 - val_loss: 0.0082\n",
      "Epoch 10/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0080 - val_accuracy: 0.9978 - val_loss: 0.0052\n",
      "Epoch 11/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0071 - val_accuracy: 0.9988 - val_loss: 0.0032\n",
      "Epoch 12/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0076 - val_accuracy: 0.9982 - val_loss: 0.0049\n",
      "Epoch 13/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0071 - val_accuracy: 0.9990 - val_loss: 0.0031\n",
      "Epoch 14/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0069 - val_accuracy: 0.9992 - val_loss: 0.0029\n",
      "Epoch 15/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0064 - val_accuracy: 0.9992 - val_loss: 0.0026\n",
      "Epoch 16/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0062 - val_accuracy: 0.9989 - val_loss: 0.0029\n",
      "Epoch 17/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0061 - val_accuracy: 0.9990 - val_loss: 0.0028\n",
      "Epoch 18/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0056 - val_accuracy: 0.9991 - val_loss: 0.0024\n",
      "Epoch 19/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0056 - val_accuracy: 0.9990 - val_loss: 0.0032\n",
      "Epoch 20/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0050 - val_accuracy: 0.9986 - val_loss: 0.0037\n",
      "Epoch 21/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0055 - val_accuracy: 0.9982 - val_loss: 0.0039\n",
      "Epoch 22/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0051 - val_accuracy: 0.9988 - val_loss: 0.0031\n",
      "Epoch 23/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0047 - val_accuracy: 0.9993 - val_loss: 0.0022\n",
      "Epoch 24/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0050 - val_accuracy: 0.9989 - val_loss: 0.0033\n",
      "Epoch 25/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0046 - val_accuracy: 0.9995 - val_loss: 0.0019\n",
      "Epoch 26/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0044 - val_accuracy: 0.9991 - val_loss: 0.0019\n",
      "Epoch 27/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0044 - val_accuracy: 0.9997 - val_loss: 0.0011\n",
      "Epoch 28/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0042 - val_accuracy: 0.9988 - val_loss: 0.0033\n",
      "Epoch 29/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0040 - val_accuracy: 0.9990 - val_loss: 0.0027\n",
      "Epoch 30/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0045 - val_accuracy: 0.9958 - val_loss: 0.0134\n",
      "Epoch 31/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0042 - val_accuracy: 0.9996 - val_loss: 0.0019\n",
      "Epoch 32/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0036 - val_accuracy: 0.9998 - val_loss: 0.0013\n",
      "Epoch 33/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.9992 - val_loss: 0.0021\n",
      "Epoch 34/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0044 - val_accuracy: 0.9990 - val_loss: 0.0026\n",
      "Epoch 35/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0041 - val_accuracy: 0.9990 - val_loss: 0.0025\n",
      "Epoch 36/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 0.9989 - val_loss: 0.0026\n",
      "Epoch 37/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0038 - val_accuracy: 0.9988 - val_loss: 0.0036\n",
      "Epoch 38/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.9987 - val_loss: 0.0033\n",
      "Epoch 39/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0036 - val_accuracy: 0.9995 - val_loss: 0.0017\n",
      "Epoch 40/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.9979 - val_loss: 0.0063\n",
      "Epoch 41/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.9996 - val_loss: 0.0014\n",
      "Epoch 42/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.9993 - val_loss: 0.0017\n",
      "Epoch 43/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 0.9994 - val_loss: 0.0015\n",
      "Epoch 44/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.9994 - val_loss: 0.0017\n",
      "Epoch 45/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0034 - val_accuracy: 0.9978 - val_loss: 0.0052\n",
      "Epoch 46/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.9998 - val_loss: 8.6230e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0034 - val_accuracy: 0.9996 - val_loss: 0.0014\n",
      "Epoch 48/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0032 - val_accuracy: 0.9993 - val_loss: 0.0022\n",
      "Epoch 49/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 0.9995 - val_loss: 0.0013\n",
      "Epoch 50/50\n",
      "\u001b[1m4089/4089\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9992 - val_loss: 0.0026\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(X_train_resampled.shape[1],)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification (0 or 1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_resampled, y_train_resampled, epochs=50, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67I8IDBVqoSa"
   },
   "source": [
    "# Testing and Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XpC2mEYbBnlB",
    "outputId": "54dd5f67-161b-4bbb-9590-f1516149b5f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0025\n",
      "Test Accuracy: 99.92%\n",
      "\u001b[1m2038/2038\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "Precision: 0.9948946339343906\n",
      "Recall: 0.9996725605762934\n",
      "F1 Score: 0.9972778745644599\n",
      "[[55996    47]\n",
      " [    3  9159]]\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "print(f\"Precision: {precision_score(y_test, y_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred)}\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JFE1ZO10VHCb",
    "outputId": "87049d54-2666-4b47-fd3d-620076625d3d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model to the runtime (local file system)\n",
    "model.save('/content/cleemate-model.h5')"
   ]
  },
